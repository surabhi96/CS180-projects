<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Image Warping and Mosaicing - Part I</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
    h1, h2, h3 { margin-top: 40px; }
    img { max-width: 400px; margin: 10px; border: 1px solid #ccc; }
    .section { margin-bottom: 60px; }
  </style>
</head>
<body>

<h1>Image Warping and Mosaicing - Part I</h1>

<div class="section">
<h2>A.1: Shoot the Pictures</h2>

<p>
  Images are taken from the courtyard of a building complex by rotating the camera such that the camera center remains fixed. 
  The images are good candidates for creating a mosaic as they naturally contain a lot of corners due to vertical and horizontal line intersections. 
</p>

<img src="data/left.jpeg" alt="left image">
<img src="data/middle.jpeg" alt="middle image">
<img src="data/right.jpeg" alt="right image">
</div>
<div>
<h2>A.2: Recover Homographies</h2>
<p>To compute the homography between two images, the correspondences are first marked manually and stored in a txt file.</p>

<img src="results/corresps_left.jpeg" alt="Gradient magnitude" width="600">
<br>
<img src="results/corresps_right.jpeg" alt="Gradient magnitude" width="600">

<!-- <img src="results/corresps_left.jpeg" alt="Gradient magnitude" width="2400" height="350">
<img src="results/corresps_right.jpeg" alt="Gradient magnitude" width="2400" height="350"> -->
<p>Once 1-1 point to point correspondences are established, homography is computed via least squares. 
  Below is the code snippet along with comments that compute the homography matrix.</p>
<h3>Compute homography</h3>
<pre><code>
  def compute_homography(pts1_n, pts2_n):
    A = []
    # Populate the A matrix to form Ah = 0 
    for (x, y), (u, v) in zip(pts1_n, pts2_n):
        A.append([x, y, 1, 0, 0, 0, -u*x, -u*y, -u])
        A.append([0, 0, 0, x, y, 1, -v*x, -v*y, -v])
    A = np.array(A)
    # Compute the SVD of A
    U, S, Vt = np.linalg.svd(A)
    # Last column of V or last row of V transpose is the least squares solution to Ah = 0
    H = Vt[-1,:].reshape(3,3)
    # The scale is factored out from the homography matrix
    H /= H[-1,-1]
    return H
</code></pre>
<h3>Estimated homography between left and mid image</h3>
<pre><code>
 [[ 1.69867416e+00  4.05641368e-02 -1.20704547e+03]
 [ 2.37761687e-01  1.43178785e+00 -5.77526132e+02]
 [ 1.65231738e-04  2.09763667e-05  1.00000000e+00]]
</code></pre>
<h3>Estimated homography between right and mid image</h3>
<pre><code>
 [[ 5.07890256e-01  4.81447356e-03  8.33327316e+02]
 [-2.01050693e-01  7.71031301e-01  3.65449108e+02]
 [-1.21041275e-04 -4.04771370e-06  1.00000000e+00]]
</code></pre>
</div>
<div>
<h2>A.3: Warp the Images</h2>
  <p>In this section, a planar object in the projective plane i.e. image plane is transformed to a
    front facing plane with dimensions of choice. Inverse Warping is used to avoid holes and two 
    different techniques are tested for interpolation.  </p>
    <img src="results/A_3_eg1.jpeg" alt="Comparing nn with bilinear interp" width="600">
    <table border="1" cellspacing="0" cellpadding="5" style="margin-top:10px; border-collapse:collapse; text-align:center;">
      <tr style="background-color:#f0f0f0;">
        <th>Interpolation Method</th>
        <th>Visual Quality</th>
        <th>Computation Time (ms)</th>
      </tr>
      <tr>
        <td>Nearest Neighbor</td>
        <td>Pixelated edges, blocky artifacts</td>
        <td>7.9 (Faster)</td>
      </tr>
      <tr>
        <td>Bilinear Interpolation</td>
        <td>Smoother transitions, better continuity</td>
        <td>15.3 (Slower)</td>
      </tr>
    </table>
<div>
<h2>A.4: Blend the Images into a Mosaic</h2>
<p> The three images shown in section A.4 were used to create a mosaic. The procedure is briefly explained below </p>
<ul>
  <li>Warp each image to the middle or center frame using the computed homographies.</li>
  <li>Compute the bounds of the canvas that will constitute the output blended image consisting of all the frames by getting the min and max values of the warped image corners. </li>
  <li>Each warped image will have to be translated according to the min bounds computed above to accomodate the entire extent of the input images within the final output. </li>
  <li>Compute the corresponding binary masks for each warped image.</li>
  <li>To blend these warped images seamlessly, two methods are explored - weighted average and feathering technique.</li>
  <li>Weighted average blends by proportional contribution of overlapping pixels. The seams between the images can be seen slightly (especially on the left white wall above the fireplace). This is exaggerated further for easy viewing.</li>
  <img src="results/weighted_avg.jpg" alt="weighted average">
  <img src="results/pre_blend.jpg" alt="weighted average ex">
  <li>Feathering blends softly near boundaries using gradual fall-off weights. Distance based weights to minimize visible seams as shown below.</li>
  <img src="results/feather_blend.jpg" alt="Comparison of weighted average and feathering" width="600">
  <li>It can be noticed that there is some blurring (tree leaves) and ghosting (chairs - center right). This can be attributed to the input data. All attempts were made to not translate the camera center but this cannot be 100% guaranteed with hand held capture. </li>
</ul>
</div>

</body>
</html>
